{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home assigment von Alfons Dauer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.read_csv(\"validation.csv\")\n",
    "train = pd.read_csv(\"training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3700, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us take a first look into the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>v1;\"v2\";\"v3\";\"v4\";\"v5\";\"v6\";\"v7\";\"v8\";\"v9\";\"v10\";\"v11\";\"v12\";\"v13\";\"v14\";\"v15\";\"v17\";\"v18\";\"v19\";\"classLabel\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a;17</th>\n",
       "      <th>92;5</th>\n",
       "      <th>4e-05;\"u\";\"g\";\"c\";\"v\";1</th>\n",
       "      <td>75;\"f\";\"t\";1;\"t\";\"g\";80;5;8e+05;\"t\";0;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;16</th>\n",
       "      <th>92;3</th>\n",
       "      <th>35e-05;\"y\";\"p\";\"k\";\"v\";0</th>\n",
       "      <td>29;\"f\";\"f\";0;\"f\";\"s\";200;0;2e+06;NA;0;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;31</th>\n",
       "      <th>25;0</th>\n",
       "      <th>0001125;\"u\";\"g\";\"ff\";\"ff\";0;\"f\";\"t\";1;\"f\";\"g\";96;19;960000;\"t\";0;\"no.\"</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a;48</th>\n",
       "      <th>17;0</th>\n",
       "      <th>0001335;\"u\";\"g\";\"i\";\"o\";0</th>\n",
       "      <td>335;\"f\";\"f\";0;\"f\";\"g\";0;120;0;NA;0;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;32</th>\n",
       "      <th>33;0</th>\n",
       "      <th>00035;\"u\";\"g\";\"k\";\"v\";0</th>\n",
       "      <td>5;\"f\";\"f\";0;\"t\";\"g\";232;0;2320000;\"f\";0;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a;34</th>\n",
       "      <th>83;0</th>\n",
       "      <th>000125;\"y\";\"p\";\"i\";\"h\";0</th>\n",
       "      <td>5;\"f\";\"f\";0;\"t\";\"g\";160;0;1600000;\"f\";0;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a;26</th>\n",
       "      <th>17;2e-04;\"u\";\"g\";\"j\";\"j\";0;\"f\";\"f\";0;\"t\";\"g\";276;1;2760000;NA;0;\"no.\"</th>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;21</th>\n",
       "      <th>17;8</th>\n",
       "      <th>75e-05;\"y\";\"p\";\"c\";\"h\";0</th>\n",
       "      <td>25;\"f\";\"f\";0;\"f\";\"g\";280;204;2800000;NA;0;\"no.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                           v1;\"v2\";\"v3\";\"v4\";\"v5\";\"v6\";\"v7\";\"v8\";\"v9\";\"v10\";\"v11\";\"v12\";\"v13\";\"v14\";\"v15\";\"v17\";\"v18\";\"v19\";\"classLabel\"\n",
       "a;17 92;5                                               4e-05;\"u\";\"g\";\"c\";\"v\";1                                   75;\"f\";\"t\";1;\"t\";\"g\";80;5;8e+05;\"t\";0;\"no.\"                                                           \n",
       "b;16 92;3                                               35e-05;\"y\";\"p\";\"k\";\"v\";0                                  29;\"f\";\"f\";0;\"f\";\"s\";200;0;2e+06;NA;0;\"no.\"                                                           \n",
       "b;31 25;0                                               0001125;\"u\";\"g\";\"ff\";\"ff\";0;\"f\";\"t\";1;\"f\";\"g\";9...                                                NaN                                                           \n",
       "a;48 17;0                                               0001335;\"u\";\"g\";\"i\";\"o\";0                                    335;\"f\";\"f\";0;\"f\";\"g\";0;120;0;NA;0;\"no.\"                                                           \n",
       "b;32 33;0                                               00035;\"u\";\"g\";\"k\";\"v\";0                                 5;\"f\";\"f\";0;\"t\";\"g\";232;0;2320000;\"f\";0;\"no.\"                                                           \n",
       "a;34 83;0                                               000125;\"y\";\"p\";\"i\";\"h\";0                                5;\"f\";\"f\";0;\"t\";\"g\";160;0;1600000;\"f\";0;\"no.\"                                                           \n",
       "a;26 17;2e-04;\"u\";\"g\";\"j\";\"j\";0;\"f\";\"f\";0;\"t\";\"g\";27... NaN                                                                                               NaN                                                           \n",
       "b;21 17;8                                               75e-05;\"y\";\"p\";\"c\";\"h\";0                              25;\"f\";\"f\";0;\"f\";\"g\";280;204;2800000;NA;0;\"no.\"                                                           "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a)\n",
    "This doesen't look nice. First things that got my attention:\n",
    "\n",
    "1. The columns have to be seperated from one another.\n",
    "2. There are multiple index and some information is written into the index. Also I do not know if there is in fact a real index or not. I will just interpret everything as a variable. If there is indeed an index somewhere and the data set is ordered it could lead to a problem. I will have to keep that in mind.\n",
    "3. The variable names are non-descriptive. This leads to: \n",
    "    - feature engineering with a priori knowledge is impossible\n",
    "    - we don't know if some variables are rounded and continuous or categorical/ordinal\n",
    "    - we don't know if false positives and false negatives have the same cost\n",
    "    - no way of interpreting the results\n",
    "\n",
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1691"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train.isnull().any(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats a lot of rows with missing values considering we only have 3700 rows to begin with. Trying to recover the missing values could be worth the hassle but for this we need to find out what variables are acutally missing. So i just drop them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1b) \n",
    "So far i don't find it necessary to remove features since we don't have that many, even if some are probably useless like the one with a bunch of zeros in front. Also the variable 'v18' has a lot of NAs but since it is categorical i will just remove it after one-hot encoding the available information of that variable.\n",
    "\n",
    "## 2.\n",
    "Now let us explore the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>v1;\"v2\";\"v3\";\"v4\";\"v5\";\"v6\";\"v7\";\"v8\";\"v9\";\"v10\";\"v11\";\"v12\";\"v13\";\"v14\";\"v15\";\"v17\";\"v18\";\"v19\";\"classLabel\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b;32</th>\n",
       "      <th>33;0</th>\n",
       "      <th>00075;\"u\";\"g\";\"e\";\"bb\";1</th>\n",
       "      <td>585;\"t\";\"f\";0;\"t\";\"s\";420;0;4200000;NA;1;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;23</th>\n",
       "      <th>58;0</th>\n",
       "      <th>000179;\"u\";\"g\";\"c\";\"v\";0</th>\n",
       "      <td>54;\"f\";\"f\";0;\"t\";\"g\";136;1;1360000;NA;0;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;36</th>\n",
       "      <th>42;7</th>\n",
       "      <th>5e-05;\"y\";\"p\";\"d\";\"v\";0</th>\n",
       "      <td>585;\"f\";\"f\";0;\"f\";\"g\";240;3;2400000;NA;1;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;18</th>\n",
       "      <th>42;0</th>\n",
       "      <th>0010415;\"y\";\"p\";\"aa\";\"v\";0</th>\n",
       "      <td>125;\"t\";\"f\";0;\"f\";\"g\";120;375;1200000;NA;0;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;24</th>\n",
       "      <th>5;0</th>\n",
       "      <th>0013335;\"y\";\"p\";\"aa\";\"v\";0</th>\n",
       "      <td>04;\"f\";\"f\";0;\"t\";\"g\";120;475;1200000;\"f\";1;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a;39</th>\n",
       "      <th>08;4e-04;\"u\";\"g\";\"c\";\"v\";3;\"f\";\"f\";0;\"f\";\"g\";480;0;4800000;\"f\";0;\"no.\"</th>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;23</th>\n",
       "      <th>42;1e-04;\"u\";\"g\";\"c\";\"v\";0</th>\n",
       "      <th>5;\"f\";\"f\";0;\"t\";\"s\";280;0;2800000;NA;1;\"no.\"</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;29</th>\n",
       "      <th>58;0</th>\n",
       "      <th>000475;\"u\";\"g\";\"m\";\"v\";2;\"f\";\"t\";1;\"t\";\"g\";460;68;4600000;\"t\";0;\"no.\"</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                           v1;\"v2\";\"v3\";\"v4\";\"v5\";\"v6\";\"v7\";\"v8\";\"v9\";\"v10\";\"v11\";\"v12\";\"v13\";\"v14\";\"v15\";\"v17\";\"v18\";\"v19\";\"classLabel\"\n",
       "b;32 33;0                                               00075;\"u\";\"g\";\"e\";\"bb\";1                               585;\"t\";\"f\";0;\"t\";\"s\";420;0;4200000;NA;1;\"no.\"                                                           \n",
       "b;23 58;0                                               000179;\"u\";\"g\";\"c\";\"v\";0                                54;\"f\";\"f\";0;\"t\";\"g\";136;1;1360000;NA;0;\"no.\"                                                           \n",
       "b;36 42;7                                               5e-05;\"y\";\"p\";\"d\";\"v\";0                                585;\"f\";\"f\";0;\"f\";\"g\";240;3;2400000;NA;1;\"no.\"                                                           \n",
       "b;18 42;0                                               0010415;\"y\";\"p\";\"aa\";\"v\";0                           125;\"t\";\"f\";0;\"f\";\"g\";120;375;1200000;NA;0;\"no.\"                                                           \n",
       "b;24 5;0                                                0013335;\"y\";\"p\";\"aa\";\"v\";0                           04;\"f\";\"f\";0;\"t\";\"g\";120;475;1200000;\"f\";1;\"no.\"                                                           \n",
       "a;39 08;4e-04;\"u\";\"g\";\"c\";\"v\";3;\"f\";\"f\";0;\"f\";\"g\";48... NaN                                                                                               NaN                                                           \n",
       "b;23 42;1e-04;\"u\";\"g\";\"c\";\"v\";0                         5;\"f\";\"f\";0;\"t\";\"s\";280;0;2800000;NA;1;\"no.\"                                                      NaN                                                           \n",
       "b;29 58;0                                               000475;\"u\";\"g\";\"m\";\"v\";2;\"f\";\"t\";1;\"t\";\"g\";460;...                                                NaN                                                           "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The findings from 1. still hold up. So again we remove the rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(validation.isnull().any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = validation.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function to tidy up the data frame\n",
    "\"\"\"\n",
    "def tidy_data(df):\n",
    "    \n",
    "    flat_data = index_to_data(df)\n",
    "    column_names = get_column_names(df)\n",
    "    \n",
    "    data = pd.DataFrame(flat_data, columns = column_names)\n",
    "    data = data.replace('\"', '', regex=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\"\"\"\n",
    "function to combine the data from all the indeces with the row data\n",
    "\"\"\"\n",
    "def index_to_data(df):\n",
    "\n",
    "    # put the data from the index into the columns\n",
    "    temp = []\n",
    "    for i in range(df.shape[0]):\n",
    "        temp.append(list(df.index[i]) + list(df.iloc[i]))\n",
    "        \n",
    "    # flatten data of every row into one list\n",
    "    flat_data = []\n",
    "    for i in range(df.shape[0]):\n",
    "        flat_data.append([x.split(';') for x in temp[i] if str(x) != 'nan'])\n",
    "        flat_data[i] = sum(flat_data[i], [])\n",
    "        \n",
    "    # check if all rows have the same length\n",
    "    len_first = len(flat_data[0]) if flat_data else None\n",
    "    assert all(len(i) == len_first for i in flat_data), \"Not all datapoints have the same number of dimensions after removing na and flattening\"\n",
    "    \n",
    "    return flat_data\n",
    "\n",
    "\"\"\"\n",
    "function to get the column names of our df\n",
    "\"\"\"\n",
    "def get_column_names(df):\n",
    "    column_names = list(df)[0].replace('\"', '').split(\";\")\n",
    "    column_names.insert(15, 'v16')\n",
    "\n",
    "    # I am not sure if the first two var are an index, i first add them as variables and maybe remove them later.\n",
    "    column_names.insert(0, 'var_ind_2')\n",
    "    column_names.insert(0, 'var_ind_1')\n",
    "    \n",
    "    return column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_train = tidy_data(train)\n",
    "tidy_val = tidy_data(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_ind_1</th>\n",
       "      <th>var_ind_2</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>...</th>\n",
       "      <th>v11</th>\n",
       "      <th>v12</th>\n",
       "      <th>v13</th>\n",
       "      <th>v14</th>\n",
       "      <th>v15</th>\n",
       "      <th>v16</th>\n",
       "      <th>v17</th>\n",
       "      <th>v18</th>\n",
       "      <th>v19</th>\n",
       "      <th>classLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>17</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>8e+05</td>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>16</td>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>35e-05</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>2e+06</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>48</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0001335</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>i</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>00035</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>2320000</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>34</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>000125</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>i</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1600000</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  var_ind_1 var_ind_2  v1 v2       v3 v4 v5 v6 v7 v8    ...     v11 v12 v13  \\\n",
       "0         a        17  92  5    4e-05  u  g  c  v  1    ...       t   1   t   \n",
       "1         b        16  92  3   35e-05  y  p  k  v  0    ...       f   0   f   \n",
       "2         a        48  17  0  0001335  u  g  i  o  0    ...       f   0   f   \n",
       "3         b        32  33  0    00035  u  g  k  v  0    ...       f   0   t   \n",
       "4         a        34  83  0   000125  y  p  i  h  0    ...       f   0   t   \n",
       "\n",
       "  v14  v15  v16      v17 v18 v19 classLabel  \n",
       "0   g   80    5    8e+05   t   0        no.  \n",
       "1   s  200    0    2e+06  NA   0        no.  \n",
       "2   g    0  120        0  NA   0        no.  \n",
       "3   g  232    0  2320000   f   0        no.  \n",
       "4   g  160    0  1600000   f   0        no.  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tidy_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can work with our classification models we transform the data to numpy arrays and one-hot encode the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function to transform the df into a matrix we can work with.\n",
    "\"\"\"\n",
    "def df_to_matrix(df, categorical_variables): # categorical_variables is a list of column names that are categorical/strings\n",
    "\n",
    "    dummy_var = dummy_encode(df, categorical_variables)\n",
    "    df = df.drop(categorical_variables, axis = 1)\n",
    "    \n",
    "    DV, IV = get_IV_DV(df, dummy_var)\n",
    "    \n",
    "    return DV, IV\n",
    "\n",
    "\"\"\"\n",
    "function to dummy encode the categorical variables\n",
    "\"\"\"\n",
    "def dummy_encode(df, categorical_variables):\n",
    "    \n",
    "    dummy_var = pd.get_dummies(df[categorical_variables], drop_first = True)\n",
    "    dummy_var = dummy_var.as_matrix()\n",
    "    \n",
    "    return dummy_var\n",
    "\n",
    "\"\"\"\n",
    "function to split the data into the independent variables and dependent variable. The DV has to be the last dummy_var\n",
    "\"\"\"\n",
    "def get_IV_DV(numeric_var, dummy_var):\n",
    "    \n",
    "    DV = dummy_var[:, dummy_var.shape[1]-1]\n",
    "    IV_dummies = dummy_var[:, :-1]\n",
    "    \n",
    "    # scale the numeric variables\n",
    "    numeric_var = numeric_var.as_matrix()\n",
    "    scaler = StandardScaler()\n",
    "    IV_numeric = scaler.fit_transform(numeric_var.astype(float))\n",
    "    \n",
    "    IV = np.c_[IV_numeric, IV_dummies]\n",
    "    \n",
    "    return DV, IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#drop rows with NAs except if NA is in v18.\n",
    "tidy_train = tidy_train[~tidy_train.drop('v18', axis = 1).eq('NA').any(1)]\n",
    "tidy_val = tidy_val[~tidy_val.drop('v18', axis = 1).eq('NA').any(1)]\n",
    "\n",
    "# concatenate train and val data for one-hot encoding\n",
    "concatenation_point = tidy_train.shape[0]\n",
    "tidy_data = pd.concat([tidy_train, tidy_val])\n",
    "\n",
    "categorical_variables = ['var_ind_1', 'v4', 'v5', 'v6', 'v7', 'v10', 'v11', 'v13', 'v14', 'v18', 'classLabel']\n",
    "\n",
    "DV, IV = df_to_matrix(tidy_data, categorical_variables)\n",
    "\n",
    "# reverse the concatenation\n",
    "DV_train = DV[:concatenation_point]\n",
    "IV_train = IV[:concatenation_point,:]\n",
    "\n",
    "DV_val = DV[concatenation_point:]\n",
    "IV_val = IV[concatenation_point:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the data is ready for our models. First things first: Check how often every class appears in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=uint8), array([ 215, 1862], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(DV, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are very unbalanced. There are a couple ways we can deal with this. I try simple oversampling first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "IV_resampled, DV_resampled = ros.fit_resample(IV_train, DV_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build a model\n",
    "(NAs were already removed)\n",
    "\n",
    "One typically uses a logistic regression as a first model to try in binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(penalty = 'l2', random_state=0, solver = 'lbfgs').fit(IV_resampled, DV_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy on training data\n",
    "lr.score(IV_resampled, DV_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48360655737704916"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy on test data\n",
    "lr.score(IV_val, DV_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 41 artists>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the coefficients\n",
    "import matplotlib.pyplot\n",
    "plt.pyplot.bar(range(len(lr.coef_[0])), lr.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hopelessly overfit on the training data. Plotting the coefficients we see that the model is basically only looking at the variable 'v10'. Unfortunately, the connection between v10 and classLabel only exists in the training data. So I drop the variable and retrain the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "IV_resampled = np.delete(IV_resampled, 10, 1)\n",
    "IV_val = np.delete(IV_val, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8896570796460177"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty = 'l2', random_state=0, solver = 'lbfgs').fit(IV_resampled, DV_resampled)\n",
    "lr.score(IV_resampled, DV_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8934426229508197"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(IV_val, DV_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha! it seems that removing that feature was all we needed to do to get a working model. We get an accuracy of 89% on our validation set. Comparing it to the accuracy in our training set suggests that we don't overfit.\n",
    "\n",
    "Of course accuracy is not the best metric in our unbalanced data set. For a better assessement let us look at the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60,  8],\n",
       "       [ 5, 49]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred_val = lr.predict(IV_val)\n",
    "confusion_matrix(DV_val, pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio seems decent. We get a precision of 0.88 and a recall of 0.92.\n",
    "\n",
    "With more time i could try other things to get better predictions.\n",
    "Let us see the new coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 40 artists>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pyplot.bar(range(len(lr.coef_[0])), lr.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbesserungsmöglichkeiten\n",
    "(nach Priorität geordnet)\n",
    "### Predictive Modeling:\n",
    "\n",
    "- Irgendwie in Erfahrung bringen, was die Variablen eigentlich repräsentieren. Anschließend Feature Engineering.\n",
    "- Modell anpassen, falls False Positives und False Negatives verschieden viele Kosten verursachen.\n",
    "- mehr Modelle/mehr Hyperparametertuning wie z. B. tree based models, SVMs ausprobieren. In diesem Fall würden wir mehrere Modelle testen und brauchen dann neben dem Validationsset noch ein Testset. Mit CrossValidation/nested CrossValidation arbeiten macht auch Sinn.\n",
    "- Besser mit den NA Werten umgehen, anstatt die entsprechenden Zeilen einfach aus dem Modell zu schmeißen. Z.B. anhand der Sequenz herausfinden, welche Variablen in jeder Zeile fehlen und dann evtl. entsprechende Variablen rausschmeißen oder versuchen NaNs zu approximieren.\n",
    "- Weitere Metriken neben Genauigkeit zur Evaluation des Algorithmus heranziehen. Zum Beispiel ROC-AUC. Das ist nicht so mega wichtig mMn, weil die Confusion Matrix uns doch recht solide Ergebnisse gezeigt hat.\n",
    "- Anders mit den Unbalancierten Klassen umgehen. Z.B. SMOTE, ROC oder kostensensitive Lossfunktionen. Letzteres ist auch nützlich falls False Positives und False Negatives mit verschieden viel Kosten verbunden sind\n",
    "- Ausreißer finden und passende Maßnahmen ergreifen. Niedrige Priorität weil es gar nicht so einfach ist, sie zu finden und Logistische Regression ist sowieso relativ robust gegen Ausreißer.\n",
    "\n",
    "### Data Pipeline:\n",
    "- Falls gute Ergebnisse sehr wichtig sind evtl. versuchen mehr Daten aufzutreiben.\n",
    "- Pipeline verallgemeinern: Falls man erwarten kann, dass man immer mal wieder Datensets mit ähnlicher Struktur erhält den Datencleaning Prozess verallgemeinern.\n",
    "- Unit Tests, Assert Lines\n",
    "- Benutze Alternative zu as_matrix\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
