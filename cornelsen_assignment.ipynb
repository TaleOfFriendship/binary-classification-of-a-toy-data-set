{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home assigment von Alfons Dauer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.read_csv(\"validation.csv\")\n",
    "train = pd.read_csv(\"training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3700, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us take a first look into the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>v1;\"v2\";\"v3\";\"v4\";\"v5\";\"v6\";\"v7\";\"v8\";\"v9\";\"v10\";\"v11\";\"v12\";\"v13\";\"v14\";\"v15\";\"v17\";\"v18\";\"v19\";\"classLabel\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a;17</th>\n",
       "      <th>92;5</th>\n",
       "      <th>4e-05;\"u\";\"g\";\"c\";\"v\";1</th>\n",
       "      <td>75;\"f\";\"t\";1;\"t\";\"g\";80;5;8e+05;\"t\";0;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;16</th>\n",
       "      <th>92;3</th>\n",
       "      <th>35e-05;\"y\";\"p\";\"k\";\"v\";0</th>\n",
       "      <td>29;\"f\";\"f\";0;\"f\";\"s\";200;0;2e+06;NA;0;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;31</th>\n",
       "      <th>25;0</th>\n",
       "      <th>0001125;\"u\";\"g\";\"ff\";\"ff\";0;\"f\";\"t\";1;\"f\";\"g\";96;19;960000;\"t\";0;\"no.\"</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a;48</th>\n",
       "      <th>17;0</th>\n",
       "      <th>0001335;\"u\";\"g\";\"i\";\"o\";0</th>\n",
       "      <td>335;\"f\";\"f\";0;\"f\";\"g\";0;120;0;NA;0;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;32</th>\n",
       "      <th>33;0</th>\n",
       "      <th>00035;\"u\";\"g\";\"k\";\"v\";0</th>\n",
       "      <td>5;\"f\";\"f\";0;\"t\";\"g\";232;0;2320000;\"f\";0;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a;34</th>\n",
       "      <th>83;0</th>\n",
       "      <th>000125;\"y\";\"p\";\"i\";\"h\";0</th>\n",
       "      <td>5;\"f\";\"f\";0;\"t\";\"g\";160;0;1600000;\"f\";0;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a;26</th>\n",
       "      <th>17;2e-04;\"u\";\"g\";\"j\";\"j\";0;\"f\";\"f\";0;\"t\";\"g\";276;1;2760000;NA;0;\"no.\"</th>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;21</th>\n",
       "      <th>17;8</th>\n",
       "      <th>75e-05;\"y\";\"p\";\"c\";\"h\";0</th>\n",
       "      <td>25;\"f\";\"f\";0;\"f\";\"g\";280;204;2800000;NA;0;\"no.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                           v1;\"v2\";\"v3\";\"v4\";\"v5\";\"v6\";\"v7\";\"v8\";\"v9\";\"v10\";\"v11\";\"v12\";\"v13\";\"v14\";\"v15\";\"v17\";\"v18\";\"v19\";\"classLabel\"\n",
       "a;17 92;5                                               4e-05;\"u\";\"g\";\"c\";\"v\";1                                   75;\"f\";\"t\";1;\"t\";\"g\";80;5;8e+05;\"t\";0;\"no.\"                                                           \n",
       "b;16 92;3                                               35e-05;\"y\";\"p\";\"k\";\"v\";0                                  29;\"f\";\"f\";0;\"f\";\"s\";200;0;2e+06;NA;0;\"no.\"                                                           \n",
       "b;31 25;0                                               0001125;\"u\";\"g\";\"ff\";\"ff\";0;\"f\";\"t\";1;\"f\";\"g\";9...                                                NaN                                                           \n",
       "a;48 17;0                                               0001335;\"u\";\"g\";\"i\";\"o\";0                                    335;\"f\";\"f\";0;\"f\";\"g\";0;120;0;NA;0;\"no.\"                                                           \n",
       "b;32 33;0                                               00035;\"u\";\"g\";\"k\";\"v\";0                                 5;\"f\";\"f\";0;\"t\";\"g\";232;0;2320000;\"f\";0;\"no.\"                                                           \n",
       "a;34 83;0                                               000125;\"y\";\"p\";\"i\";\"h\";0                                5;\"f\";\"f\";0;\"t\";\"g\";160;0;1600000;\"f\";0;\"no.\"                                                           \n",
       "a;26 17;2e-04;\"u\";\"g\";\"j\";\"j\";0;\"f\";\"f\";0;\"t\";\"g\";27... NaN                                                                                               NaN                                                           \n",
       "b;21 17;8                                               75e-05;\"y\";\"p\";\"c\";\"h\";0                              25;\"f\";\"f\";0;\"f\";\"g\";280;204;2800000;NA;0;\"no.\"                                                           "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a)\n",
    "This doesen't look nice. First things that got my attention:\n",
    "\n",
    "1. We have missing values\n",
    "2. The columns have to be seperated from one another.\n",
    "3. There are multiple index and some information is written into them. Also I do not know if there is in fact a real index or not. The first one seems real so i will keep it as an index. (I tried it later as a variable and it did improve the model by 5% accuracy but since i don't know whether it is an index or not and i am afraid of data leakage i did not keep it in my final model)\n",
    "4. The variable names are non-descriptive. This leads to: \n",
    "    - feature engineering with a priori knowledge is impossible\n",
    "    - we don't know if some variables are rounded and continuous or categorical/ordinal\n",
    "    - we don't know if false positives and false negatives have the same cost\n",
    "    - no way of interpreting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1691"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train.isnull().any(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats a lot of rows with missing values considering we only have 3700 rows to begin with. Trying to recover the missing values could be worth the hassle but for this we need to find out what variables are acutally missing and i would need more time. So i just drop them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1b) \n",
    "So far i don't find it necessary to remove features since we don't have that many, even if some are probably useless like the one with a bunch of zeros in front. Also the variable 'v18' has a lot of NAs but since it is categorical i will just remove it after one-hot encoding the available information of that variable.\n",
    "\n",
    "## 2.\n",
    "Now let us explore the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>v1;\"v2\";\"v3\";\"v4\";\"v5\";\"v6\";\"v7\";\"v8\";\"v9\";\"v10\";\"v11\";\"v12\";\"v13\";\"v14\";\"v15\";\"v17\";\"v18\";\"v19\";\"classLabel\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b;32</th>\n",
       "      <th>33;0</th>\n",
       "      <th>00075;\"u\";\"g\";\"e\";\"bb\";1</th>\n",
       "      <td>585;\"t\";\"f\";0;\"t\";\"s\";420;0;4200000;NA;1;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;23</th>\n",
       "      <th>58;0</th>\n",
       "      <th>000179;\"u\";\"g\";\"c\";\"v\";0</th>\n",
       "      <td>54;\"f\";\"f\";0;\"t\";\"g\";136;1;1360000;NA;0;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;36</th>\n",
       "      <th>42;7</th>\n",
       "      <th>5e-05;\"y\";\"p\";\"d\";\"v\";0</th>\n",
       "      <td>585;\"f\";\"f\";0;\"f\";\"g\";240;3;2400000;NA;1;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;18</th>\n",
       "      <th>42;0</th>\n",
       "      <th>0010415;\"y\";\"p\";\"aa\";\"v\";0</th>\n",
       "      <td>125;\"t\";\"f\";0;\"f\";\"g\";120;375;1200000;NA;0;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;24</th>\n",
       "      <th>5;0</th>\n",
       "      <th>0013335;\"y\";\"p\";\"aa\";\"v\";0</th>\n",
       "      <td>04;\"f\";\"f\";0;\"t\";\"g\";120;475;1200000;\"f\";1;\"no.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a;39</th>\n",
       "      <th>08;4e-04;\"u\";\"g\";\"c\";\"v\";3;\"f\";\"f\";0;\"f\";\"g\";480;0;4800000;\"f\";0;\"no.\"</th>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;23</th>\n",
       "      <th>42;1e-04;\"u\";\"g\";\"c\";\"v\";0</th>\n",
       "      <th>5;\"f\";\"f\";0;\"t\";\"s\";280;0;2800000;NA;1;\"no.\"</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;29</th>\n",
       "      <th>58;0</th>\n",
       "      <th>000475;\"u\";\"g\";\"m\";\"v\";2;\"f\";\"t\";1;\"t\";\"g\";460;68;4600000;\"t\";0;\"no.\"</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                           v1;\"v2\";\"v3\";\"v4\";\"v5\";\"v6\";\"v7\";\"v8\";\"v9\";\"v10\";\"v11\";\"v12\";\"v13\";\"v14\";\"v15\";\"v17\";\"v18\";\"v19\";\"classLabel\"\n",
       "b;32 33;0                                               00075;\"u\";\"g\";\"e\";\"bb\";1                               585;\"t\";\"f\";0;\"t\";\"s\";420;0;4200000;NA;1;\"no.\"                                                           \n",
       "b;23 58;0                                               000179;\"u\";\"g\";\"c\";\"v\";0                                54;\"f\";\"f\";0;\"t\";\"g\";136;1;1360000;NA;0;\"no.\"                                                           \n",
       "b;36 42;7                                               5e-05;\"y\";\"p\";\"d\";\"v\";0                                585;\"f\";\"f\";0;\"f\";\"g\";240;3;2400000;NA;1;\"no.\"                                                           \n",
       "b;18 42;0                                               0010415;\"y\";\"p\";\"aa\";\"v\";0                           125;\"t\";\"f\";0;\"f\";\"g\";120;375;1200000;NA;0;\"no.\"                                                           \n",
       "b;24 5;0                                                0013335;\"y\";\"p\";\"aa\";\"v\";0                           04;\"f\";\"f\";0;\"t\";\"g\";120;475;1200000;\"f\";1;\"no.\"                                                           \n",
       "a;39 08;4e-04;\"u\";\"g\";\"c\";\"v\";3;\"f\";\"f\";0;\"f\";\"g\";48... NaN                                                                                               NaN                                                           \n",
       "b;23 42;1e-04;\"u\";\"g\";\"c\";\"v\";0                         5;\"f\";\"f\";0;\"t\";\"s\";280;0;2800000;NA;1;\"no.\"                                                      NaN                                                           \n",
       "b;29 58;0                                               000475;\"u\";\"g\";\"m\";\"v\";2;\"f\";\"t\";1;\"t\";\"g\";460;...                                                NaN                                                           "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The findings from 1. hold up for the most part. The leftmost index has duplicates already in the header which makes it unlikely that it is an index. Again we remove the rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(validation.isnull().any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = validation.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function to tidy up the data frame\n",
    "\"\"\"\n",
    "def tidy_data(df):\n",
    "    \n",
    "    flat_data = index_to_data(df)\n",
    "    column_names = get_column_names(df)\n",
    "    index_names = get_index_names(df)\n",
    "    \n",
    "    data = pd.DataFrame(flat_data, columns = column_names, index = index_names)\n",
    "    data = data.replace('\"', '', regex=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\"\"\"\n",
    "function to combine the data from all the indeces with the row data\n",
    "\"\"\"\n",
    "def index_to_data(df):\n",
    "\n",
    "    # put the data from the index into the columns\n",
    "    temp = []\n",
    "    for i in range(df.shape[0]):\n",
    "        temp.append(list(df.index[i][1:]) + list(df.iloc[i]))\n",
    "        \n",
    "    # flatten data of every row into one list\n",
    "    flat_data = []\n",
    "    for i in range(df.shape[0]):\n",
    "        flat_data.append([x.split(';') for x in temp[i] if str(x) != 'nan'])\n",
    "        flat_data[i] = sum(flat_data[i], [])\n",
    "        \n",
    "    # check if all rows have the same length\n",
    "    len_first = len(flat_data[0]) if flat_data else None\n",
    "    assert all(len(i) == len_first for i in flat_data), \"Not all datapoints have the same number of dimensions after removing na and flattening\"\n",
    "    \n",
    "    return flat_data\n",
    "\n",
    "\"\"\"\n",
    "function to get the column names of our df\n",
    "\"\"\"\n",
    "def get_column_names(df):\n",
    "    column_names = list(df)[0].replace('\"', '').split(\";\")\n",
    "    column_names.insert(15, 'v16')\n",
    "    \n",
    "    return column_names\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "function to get the index names of our df\n",
    "\"\"\"\n",
    "def get_index_names(df):\n",
    "    \n",
    "    # for some reason the vectorized version does not work so i use a for loop\n",
    "    index_names = []\n",
    "    for i in range(df.shape[0]):\n",
    "        index_names.append(train.index[i][0])\n",
    "\n",
    "    return index_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy_train = tidy_data(train)\n",
    "tidy_val = tidy_data(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>v11</th>\n",
       "      <th>v12</th>\n",
       "      <th>v13</th>\n",
       "      <th>v14</th>\n",
       "      <th>v15</th>\n",
       "      <th>v16</th>\n",
       "      <th>v17</th>\n",
       "      <th>v18</th>\n",
       "      <th>v19</th>\n",
       "      <th>classLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a;17</th>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>4e-05</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>8e+05</td>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;16</th>\n",
       "      <td>92</td>\n",
       "      <td>3</td>\n",
       "      <td>35e-05</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>2e+06</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a;48</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0001335</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>i</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>335</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b;32</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>00035</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>2320000</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a;34</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>000125</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>i</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1600000</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      v1 v2       v3 v4 v5 v6 v7 v8   v9 v10 v11 v12 v13 v14  v15  v16  \\\n",
       "a;17  92  5    4e-05  u  g  c  v  1   75   f   t   1   t   g   80    5   \n",
       "b;16  92  3   35e-05  y  p  k  v  0   29   f   f   0   f   s  200    0   \n",
       "a;48  17  0  0001335  u  g  i  o  0  335   f   f   0   f   g    0  120   \n",
       "b;32  33  0    00035  u  g  k  v  0    5   f   f   0   t   g  232    0   \n",
       "a;34  83  0   000125  y  p  i  h  0    5   f   f   0   t   g  160    0   \n",
       "\n",
       "          v17 v18 v19 classLabel  \n",
       "a;17    8e+05   t   0        no.  \n",
       "b;16    2e+06  NA   0        no.  \n",
       "a;48        0  NA   0        no.  \n",
       "b;32  2320000   f   0        no.  \n",
       "a;34  1600000   f   0        no.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tidy_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can work with our classification models we transform the data to numpy arrays and one-hot encode the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function to transform the df into a matrix we can work with.\n",
    "\"\"\"\n",
    "def df_to_matrix(df, categorical_variables): # categorical_variables is a list of column names that are categorical/strings\n",
    "\n",
    "    dummy_var = dummy_encode(df, categorical_variables)\n",
    "    df = df.drop(categorical_variables, axis = 1)\n",
    "    \n",
    "    DV, IV = get_IV_DV(df, dummy_var)\n",
    "    \n",
    "    return DV, IV\n",
    "\n",
    "\"\"\"\n",
    "function to dummy encode the categorical variables\n",
    "\"\"\"\n",
    "def dummy_encode(df, categorical_variables):\n",
    "    \n",
    "    dummy_var = pd.get_dummies(df[categorical_variables], drop_first = True)\n",
    "    dummy_var = dummy_var.as_matrix()\n",
    "    \n",
    "    return dummy_var\n",
    "\n",
    "\"\"\"\n",
    "function to split the data into the independent variables and dependent variable. The DV has to be the last dummy_var\n",
    "\"\"\"\n",
    "def get_IV_DV(numeric_var, dummy_var):\n",
    "    \n",
    "    DV = dummy_var[:, dummy_var.shape[1]-1]\n",
    "    IV_dummies = dummy_var[:, :-1]\n",
    "    \n",
    "    # scale the numeric variables\n",
    "    numeric_var = numeric_var.as_matrix()\n",
    "    scaler = StandardScaler()\n",
    "    IV_numeric = scaler.fit_transform(numeric_var.astype(float))\n",
    "    \n",
    "    IV = np.c_[IV_numeric, IV_dummies]\n",
    "    \n",
    "    return DV, IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#drop rows with NAs except if NA is in v18.\n",
    "tidy_train = tidy_train[~tidy_train.drop('v18', axis = 1).eq('NA').any(1)]\n",
    "tidy_val = tidy_val[~tidy_val.drop('v18', axis = 1).eq('NA').any(1)]\n",
    "\n",
    "# concatenate train and val data for one-hot encoding\n",
    "concatenation_point = tidy_train.shape[0]\n",
    "tidy_data = pd.concat([tidy_train, tidy_val])\n",
    "\n",
    "categorical_variables = ['v4', 'v5', 'v6', 'v7', 'v10', 'v11', 'v13', 'v14', 'v18', 'classLabel']\n",
    "\n",
    "DV, IV = df_to_matrix(tidy_data, categorical_variables)\n",
    "\n",
    "# reverse the concatenation\n",
    "DV_train = DV[:concatenation_point]\n",
    "IV_train = IV[:concatenation_point,:]\n",
    "\n",
    "DV_val = DV[concatenation_point:]\n",
    "IV_val = IV[concatenation_point:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the data is ready for our models. First things first: Check how often every class appears in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=uint8), array([ 220, 1879], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(DV, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are very unbalanced. There are a couple ways we can deal with this. I try simple oversampling first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "IV_resampled, DV_resampled = ros.fit_resample(IV_train, DV_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build a model\n",
    "(NAs were already removed)\n",
    "\n",
    "It is generally a good idea to use a logistic regression as a first model to try in binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.08876157, 0.0488658 , 0.05385542, 0.03091693, 0.03590655]),\n",
       " 'score_time': array([0.        , 0.00099754, 0.        , 0.0009973 , 0.0020237 ]),\n",
       " 'test_score': array([1., 1., 1., 1., 1.]),\n",
       " 'train_score': array([1., 1., 1., 1., 1.])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "lr = LogisticRegression(penalty = 'l2', random_state=0, solver = 'lbfgs')\n",
    "scores = cross_validate(lr, IV_resampled, DV_resampled, cv = 5, return_train_score = True)\n",
    "\n",
    "# accuracy on test folds from cross validation\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perfect test score seems too good to be true but since i don't know anything about the data it is possible. Let us test the model on our validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4838709677419355"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy of our model on validation data\n",
    "lr_fit = lr.fit(IV_resampled, DV_resampled)\n",
    "\n",
    "lr_fit.score(IV_val, DV_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats unfortunate, there is probably some data leakage in our train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 39 artists>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the coefficients\n",
    "import matplotlib.pyplot\n",
    "plt.pyplot.bar(range(len(lr.coef_[0])), lr.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the coefficients we see that the model is basically only looking at the variable 'v10'. The connection between v10 and classLabel only exists in the training data. So I drop the variable and retrain the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "IV_resampled = np.delete(IV_resampled, 9, 1)\n",
    "IV_val = np.delete(IV_val, 9, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain the same model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.24135494, 0.03989339, 0.04388118, 0.08477378, 0.14561105]),\n",
       " 'score_time': array([0.00099659, 0.        , 0.        , 0.        , 0.0009973 ]),\n",
       " 'test_score': array([0.86986301, 0.86712329, 0.87671233, 0.89041096, 0.87637363]),\n",
       " 'train_score': array([0.87457162, 0.88793694, 0.87114462, 0.86943112, 0.88184932])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty = 'l2', random_state=0, solver = 'lbfgs')\n",
    "scores = cross_validate(lr, IV_resampled, DV_resampled, cv = 5, return_train_score = True)\n",
    "\n",
    "# accuracy on training data\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 'test_score' and 'train_score' seem similar which is good. Now we test the model on our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8467741935483871"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy of our model on validation data\n",
    "lr_fit = lr.fit(IV_resampled, DV_resampled)\n",
    "\n",
    "lr_fit.score(IV_val, DV_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha! it seems that removing that feature was all we needed to do to get a working model. We get an accuracy of 85% on our validation set.\n",
    "\n",
    "Of course accuracy is not the best metric in our unbalanced data set. For a better assessement let us look at the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57, 12],\n",
       "       [ 7, 48]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred_val = lr.predict(IV_val)\n",
    "confusion_matrix(DV_val, pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a precision of 0.8 and a recall of 0.87. The ratio between them seems decent.\n",
    "\n",
    "With more time i could try other things to get better predictions.\n",
    "In the end let us see the new coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 38 artists>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pyplot.bar(range(len(lr.coef_[0])), lr.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbesserungsmöglichkeiten\n",
    "(nach Priorität geordnet)\n",
    "### Predictive Modeling:\n",
    "\n",
    "- Irgendwie in Erfahrung bringen, was die Variablen eigentlich repräsentieren. Anschließend Feature Engineering.\n",
    "- Modell anpassen, falls False Positives und False Negatives verschieden viele Kosten verursachen.\n",
    "- mehr Modelle/mehr Hyperparametertuning wie z. B. tree based models, SVMs ausprobieren.\n",
    "- Besser mit den NA Werten umgehen, anstatt die entsprechenden Zeilen einfach aus dem Modell zu schmeißen. Z.B. anhand der Sequenz herausfinden, welche Variablen in jeder Zeile fehlen und dann evtl. entsprechende Variablen rausschmeißen oder versuchen NaNs zu approximieren.\n",
    "- Weitere Metriken neben Genauigkeit zur Evaluation des Algorithmus heranziehen, zum Beispiel ROC-AUC, F1-score. Das ist nicht so mega wichtig mMn, weil uns die Confusion Matrix doch recht solide Ergebnisse gezeigt hat.\n",
    "- Anders mit den Unbalancierten Klassen umgehen. Z.B. SMOTE, ROC oder kostensensitive Lossfunktionen. Letzteres ist auch nützlich falls False Positives und False Negatives mit verschieden viel Kosten verbunden sind\n",
    "- Ausreißer finden und passende Maßnahmen ergreifen. Niedrige Priorität weil es gar nicht so einfach ist, sie zu finden und Logistische Regression ist sowieso relativ robust gegen Ausreißer.\n",
    "\n",
    "### Data Pipeline:\n",
    "- Falls gute Ergebnisse sehr wichtig sind evtl. versuchen mehr Daten aufzutreiben.\n",
    "- Pipeline verallgemeinern: Falls man erwarten kann, dass man immer mal wieder Datensets mit ähnlicher Struktur erhält den Datencleaning Prozess verallgemeinern.\n",
    "- Unit Tests, Assert Lines\n",
    "- Benutze Alternative zu as_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
